1. 维度灾难是指当数据的维度（特征数量）增加时，数据分析和机器学习任务变得困难的现象。在高维问题中会影响距离计算、数据分布和模型性能等多个方面。

2. 如何解决维度灾难？

   1. 降维
      采用PCA（主成分分析）、LDA（线性判别分析）等方法**降低数据维度，同时寻找原始信息**

   2. 特征选择
      通过相关系分析、Lassc回归方法去掉特征，只保留最重要的特征

   3. 正则方法

      在高维模型中，使用L1/L2正则化以避免过度

3. 维度灾难的影响
   1. 距离计算失效
      高维空间，所有点之间的距离趋近相似，导致最近邻算法（KNN）等算法失效。
   2. 数据变得稀疏
      随维度增加，数据点在高维空间中会变得越来越分散，导致统计学习方法（如聚类）变得更加困难。
   3. 计算复杂度延指数指数级增长
      许多算法（如KNN）的计算复杂度与数据维度成指数级增长，导致更多的存储空间和计算资源被占据，训练时间显著增加。
   4. 过拟合风险增加
      维度越高，每个样本在特征空间的位置越独特，容易导致模型记住训练数据，导致过拟合，从而无法实现泛化。

4. 降维：将高维数据映射到低维空间，同时尽可能保留数据的重要信息。目的是为了减少计算复杂度（降低成本）、去掉冗余信息（减少数据噪声，增强泛化能力）和避免维度灾难。

5. 降维的方法

   1. 特征选择：选择最重要的特征，丢弃无关或冗余的特征
   2. 特征提取：通过变换生成新的特征来降低维度

6. PCA（主成分分析法）是一种无监督学习方法，用于降维、特征提取和数据压缩；是通过线性变换找到数据的主要方向（通过转化坐标轴，使得数据投影到方差最大的方向）。

7. PCA基本思想

   1. 找到数据变化最大的方向（主成分）

      数据集中在哪个方向上的方差最大，就选取该方向作为新的坐标轴，从而尽最大可能保留原始信息。

   2. 正交转换坐标轴
      使新坐标轴（主成分）相互正交

   3. 降维的本质：保留主要信息，减少冗余
      选取前k个主成分（方差贡献率高）
