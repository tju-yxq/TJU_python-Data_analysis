1. 线性回归是一种统计方法，用于确定两个或多个变量之间的线性关系。其通过找出一条最佳拟合直线来描述因变量如何随一个或多个自变量的变化而变化。这条直线被称为回归线。
2. 线性回归分析的假定为以下五点
   1. 线性关系：自变量和因变量之间存在线性关系
   2. 独立性：观测值之间相互独立，不会相互影响
   3. 同方差性：在所有自变量水平上，误差项的方差是相同的
   4. 正态性：误差项服从均值为0，标准差固定的正态分布
   5. 无多重共线性：自变量之间不存在严格的线性关系

3. 最小二乘法是一种通过**最小化**预测值与实际值之间的**残差平方和**来确定模型参数最优解的数学方法。
4. Scikit-learn（Sklearn）是一个基于Python的广泛使用的机器学习库，旨在为数据挖掘和数据分析提供简单而高效的工具，支持多种监督和无监督学习，如回归降维分类聚类等，集成了数据预处理、模型评估和模型选择工具。
5. 回归评估指标有MSE（均方误差）、RMSE（均方根误差，MSE的平方更）、MAE（平均绝对误差）、R^2^（决定系数）、调整R^2^
6. 分类任务评估指标有准确率、精确率（预测为正例中真正正例的比例）、召回率（正例被召回的概率）
7. ROC曲线通过描绘特异度与召回率之间的关系来描述分类器的性能，越接近左上（特异度低，召回率高），模型性能越好。
8. AUC是ROC曲线下方的面积，反映了分类模型的整体性能，越大越好。
9. 残差分析：残差应符合正态分布，如果存在偏差则模型未充分拟合数据
10. K折交叉检验：将数据集分为K个子集，轮流每个子集作为验证集，其余K-1个子集作为训练集，重复K次，最终结果为所有K次验证的平均值。利用`sklearn.model_selection`中的`cross_val_score()`来实现
11. 学习曲线：通过展示训练集和验证集随样本数量变化的趋势，帮忙识别模型是否过拟合或者欠拟合
    1. 过拟合：训练误差小，而验证误差较高
    2. 欠拟合：训练误差和验证误差都较高
12. 模型复杂度：与模型参数的数量、模型的非线性程度相关，过高可能过拟合，过低可能欠拟合
13. 早停法：一种在训练中动态停止训练的方法，旨在防止过拟合。
    1. 工作原理：
       在训练过程中，计算每个训练轮次的训练误差和验证误差。如果验证误差不再下降或者上升则停止训练。
    2. 优点
       防止过拟合，训练集大时非常有效